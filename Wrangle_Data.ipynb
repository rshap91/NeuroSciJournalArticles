{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymongo as mongo\n",
    "import re\n",
    "\n",
    "\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, PCA, TruncatedSVD, LatentDirichletAllocation\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "from textblob import TextBlob, Word, WordList\n",
    "from gensim import models, corpora, similarities, matutils\n",
    "\n",
    "from sys import getsizeof\n",
    "import psutil\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=8589934592L, available=3163615232L, percent=63.2, used=7229947904L, free=721211392L, active=3146756096L, inactive=2442403840L, wired=1640787968L)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = mongo.MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'local', u'mydb']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = client.get_database('project4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "journals = db.collection_names()[:-1] # drop system.indexes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fixing poor naming schema from before\n",
    "for j in journals:\n",
    "    coll = db.get_collection(j)\n",
    "    coll.update_many({'Max_Topic_Name':'Attention??'}, {\"$set\":{'Max_Topic_Name':\"Attention\"}})\n",
    "    coll.update_many({},{\"$rename\": {\"Attention??\":\"Attention\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer()\n",
    "#### input can equal a list of filenames to read (or file objects)\n",
    "\n",
    "#### analyzer:\n",
    "    - default is \"word\"\n",
    "    - Extracts each interpreted \"word\" as features\n",
    "    \n",
    "#### The Analyzer is composed of 2 steps:\n",
    "\n",
    "1) Preprocessing\n",
    "    - This is the general string formatting that is done before tokenizing\n",
    "    - lowercasing, removing accents\n",
    "    - does not seem to include stemming/lemmatizing :-/??\n",
    "    - though you may be able to pass in a function that does whatever you want...\n",
    "2) Tokenizing\n",
    "    - Creating a vocabulary based on what is considered to be a \"word\"\n",
    "    - by default, all groups of 2 or more consecutive alpha-numeric characters are considered \"words\".\n",
    "        * punctuation is ignored and always splits \"words\"\n",
    "    - you can set the definition using token_pattern = regex...\n",
    "\n",
    "\n",
    "#### ngram_range:\n",
    "    - number of ngrams to consider for features\n",
    "    - format is (min, max)\n",
    "#### stop_words:\n",
    "    - can be 'english' or list of stopwords\n",
    "#### lowercase:\n",
    "    - Boolean default is True\n",
    "    \n",
    "    \n",
    "#### min_df and max_df:\n",
    "    - set min and max occurences required for each ftr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def JournalData(j):\n",
    "    cvec = CountVectorizer(stop_words='english')\n",
    "    collec = db.get_collection(j)    \n",
    "    \n",
    "    # find returns a curser which gets a list of dictionaries\n",
    "    data = collec.find({})\n",
    "    # in addition to our features include columns for Journal and Date\n",
    "    ids = []\n",
    "    journals = []\n",
    "    dates = [] \n",
    "    text_data = []\n",
    "    for i in range(data.count()):\n",
    "        doc = data.next()\n",
    "        ids.append(doc['_id'])\n",
    "        dates.append(doc['date'])\n",
    "        text_data.append(doc['text'])\n",
    "        journals.append(j)\n",
    "    return ids, journals, dates, text_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = []\n",
    "jnls = []\n",
    "dates = []\n",
    "text_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760\n",
      "760\n",
      "760\n",
      "1816\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "4752\n",
      "4752\n",
      "4752\n",
      "8040\n",
      "15528\n",
      "15528\n",
      "18672\n",
      "18672\n",
      "18672\n",
      "18672\n",
      "23160\n",
      "23160\n",
      "23160\n",
      "23160\n",
      "29072\n",
      "29072\n",
      "29072\n",
      "29072\n",
      "29072\n",
      "29072\n",
      "29072\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "35512\n",
      "40696\n",
      "40696\n",
      "46872\n",
      "46872\n",
      "46872\n",
      "46872\n",
      "46872\n",
      "46872\n",
      "46872\n",
      "46872\n",
      "46872\n",
      "46872\n",
      "46872\n",
      "46872\n",
      "46872\n",
      "46872\n",
      "46872\n",
      "46872\n",
      "55416\n",
      "55416\n",
      "55416\n",
      "55416\n",
      "55416\n",
      "55416\n",
      "55416\n",
      "55416\n",
      "55416\n",
      "55416\n",
      "55416\n",
      "55416\n",
      "55416\n",
      "55416\n",
      "63944\n",
      "63944\n",
      "63944\n",
      "63944\n",
      "63944\n",
      "63944\n",
      "63944\n",
      "63944\n",
      "63944\n",
      "63944\n",
      "63944\n",
      "73456\n",
      "73456\n",
      "73456\n",
      "73456\n",
      "82856\n",
      "82856\n",
      "82856\n",
      "82856\n",
      "82856\n",
      "82856\n",
      "82856\n",
      "82856\n",
      "82856\n",
      "82856\n",
      "82856\n",
      "82856\n",
      "97568\n",
      "97568\n",
      "97568\n",
      "97568\n",
      "97568\n",
      "97568\n",
      "97568\n",
      "97568\n",
      "97568\n",
      "97568\n",
      "97568\n",
      "97568\n",
      "97568\n",
      "97568\n",
      "97568\n",
      "97568\n",
      "97568\n",
      "97568\n",
      "97568\n",
      "114776\n",
      "114776\n",
      "114776\n",
      "114776\n",
      "114776\n",
      "114776\n",
      "114776\n",
      "114776\n",
      "114776\n",
      "114776\n",
      "114776\n",
      "114776\n",
      "114776\n",
      "114776\n",
      "114776\n",
      "114776\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "132632\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "151360\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "170328\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n",
      "206080\n"
     ]
    }
   ],
   "source": [
    "# BUILD LISTS CONTAINING ALL JOURNAL_NAMES DATES AND ARTICLES\n",
    "\n",
    "for j in journals:\n",
    "#     if j in jnls:\n",
    "#         continue\n",
    "    i, j, d, t = JournalData(j)\n",
    "    ids.extend(i)\n",
    "    jnls.extend(j)\n",
    "    dates.extend(d)\n",
    "    text_data.extend(t)\n",
    "    print(getsizeof(jnls))\n",
    "    if getsizeof(jnls) > 1000000000:\n",
    "        print('SHIT THATS BIG (THATS WHAT SHE SAID)')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25370 25370 25370 25370\n"
     ]
    }
   ],
   "source": [
    "print(len(ids), len(jnls), len(dates), len(text_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEANING TEXT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "body = re.compile(r'== ?[bB]ody ')\n",
    "\n",
    "def clean_doc(doc):\n",
    "    # needs textblob\n",
    "    \n",
    "    # GET RID OF NEWLINES\n",
    "    doc = doc.replace('\\n', ' ')\n",
    "    \n",
    "    # STRIP HEADING INFO\n",
    "    # if there's no body section, get rid of it\n",
    "    if not re.search(body, doc):\n",
    "        return None\n",
    "    mtch = re.search(body,doc)\n",
    "    # strip anything before match\n",
    "    doc = doc[mtch.start():]\n",
    "\n",
    "    # LOWERCASE!\n",
    "    doc = doc.lower()\n",
    "\n",
    "    #SINGULARIZE\n",
    "    # this seriously slows it down!\n",
    "    #doc = ' '.join([Word(w).singularize() for w in doc.split()])\n",
    "    return doc\n",
    "        \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "cleaned = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25370"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = Pool(4)\n",
    "cleaned = pool.map(clean_doc, text_data)\n",
    "pool.close()\n",
    "len(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=64390950912, available=51277963264, percent=20.4, used=16915623936, free=47475326976, active=14601842688, inactive=1771077632, buffers=63766528, cached=3738869760, shared=12230656)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# USE POOL - MUCH FASTER!\n",
    "# Obviously this takes a while...\n",
    "# Maybe too long\n",
    "# len(text_data) # 25370\n",
    "\n",
    "\n",
    "# for t in iter(text_data[idx:]):\n",
    "#     print(idx)\n",
    "#     cleaned.append(clean_doc(t))\n",
    "#     idx+=1\n",
    "# len(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# REMOVE STOP WORDS\n",
    "\n",
    "# stop_words = nltk.corpus.stopwords.words()\n",
    "# len(stop_words) # 2781 ... i think has other languages need only english\n",
    "\n",
    "# englishStopWords = None\n",
    "# with open('csvs/EngStopWords.csv', 'r') as f:\n",
    "#     englishStopWords = f.read().split(', ')\n",
    "    \n",
    "    \n",
    "# len(englishStopWords) # 174 better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('WranglingPickles/cleaned.pkl', 'rb') as f:\n",
    "    cleaned = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25327"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join With Jrnl Name and Date\n",
    "\n",
    "Joined = list(zip(ids,jnls, dates, range(len(cleaned))))\n",
    "\n",
    "\n",
    "\n",
    "# REMOVE NULLS\n",
    "Joined = [a for a in Joined if cleaned[a[3]]]\n",
    "cleaned = list(filter(None, cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## COUNTVECTORIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25327"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<25327x126439 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 26257680 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(cleaned)) # 25327\n",
    "\n",
    "\n",
    "\n",
    "cvectr = CountVectorizer(stop_words='english', min_df=10, max_df = 0.5)\n",
    "txt_ftrs = cvectr.fit_transform(cleaned)\n",
    "\n",
    "\n",
    "txt_ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = matutils.Sparse2Corpus(txt_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126439\n",
      "126438\n"
     ]
    }
   ],
   "source": [
    "wordDic = {d[1]: d[0] for d in cvectr.vocabulary_.items()}\n",
    "\n",
    "print(len(wordDic))\n",
    "print(max(wordDic.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## THINGS TO TRY:\n",
    "\n",
    "#### Summarize\n",
    "    - Apply PCA, SVD, NMF, LDA\n",
    "    - Interpret results... aka grouping?? how?\n",
    "    \n",
    "\n",
    "#### Features:\n",
    "    - POS\n",
    "    - Somehow incorporate Parse Trees?\n",
    "    \n",
    "    \n",
    "#### Beyond:\n",
    "    - Word2vec\n",
    "    - Heirarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PCA Doesn't work cuz it doesn't accept sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MEMORY ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GOING WITH NMF BECAUSE SVD TOPICS ARE CRUMMY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WHAT I SEE:\n",
    "    - Remove Plurals\n",
    "    - Adjust for Tenses\n",
    "    - Can we fuse numbers/units for measurements?\n",
    "    - Eliminate Random Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta=1, eta=0.1, init='nndsvd', l1_ratio=0.0, max_iter=200,\n",
       "  n_components=15, nls_max_iter=2000, random_state=None, shuffle=False,\n",
       "  solver='cd', sparseness=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf = NMF(init = 'nndsvd', n_components=15)\n",
    "\n",
    "nmf.fit(txt_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 126439)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = np.array([10,11,12,13,14,15,16])\n",
    "np.where(np.in1d(lst, [10,12,13]))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get top 25 significant words for each component\n",
    "top25 = {}\n",
    "\n",
    "for i in range(len(nmf.components_)):# for each component\n",
    "    # sort the words in the components by importance, but grab the original indices\n",
    "    idxs = np.argsort(nmf.components_[i])[-1:-26:-1]\n",
    "    # use idxs to extract corresponding words from wordDic\n",
    "    top25['ftr_'+str(i)] = [wordDic[i] for i in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ftr_0': ['neurons',\n",
       "  'neuron',\n",
       "  'cortex',\n",
       "  'fig',\n",
       "  'cortical',\n",
       "  'neuronal',\n",
       "  'synaptic',\n",
       "  'neurosci',\n",
       "  'firing',\n",
       "  'layer',\n",
       "  'nucleus',\n",
       "  'stimulation',\n",
       "  'responses',\n",
       "  'rat',\n",
       "  'input',\n",
       "  'excitatory',\n",
       "  'μm',\n",
       "  'inhibitory',\n",
       "  'pyramidal',\n",
       "  'interneurons',\n",
       "  'gabaergic',\n",
       "  'area',\n",
       "  'visual',\n",
       "  'dendritic',\n",
       "  'motor'],\n",
       " 'ftr_1': ['usepackage',\n",
       "  'document',\n",
       "  'end',\n",
       "  'begin',\n",
       "  'minimal',\n",
       "  'amsmath',\n",
       "  'amssymb',\n",
       "  'mathrsfs',\n",
       "  'documentclass',\n",
       "  'amsbsy',\n",
       "  'amsfonts',\n",
       "  'wasysym',\n",
       "  'oddsidemargin',\n",
       "  'upgreek',\n",
       "  '12pt',\n",
       "  'setlength',\n",
       "  '69pt',\n",
       "  'spike',\n",
       "  'fig',\n",
       "  'frac',\n",
       "  'stimulus',\n",
       "  'sf',\n",
       "  'mathrm',\n",
       "  'eq',\n",
       "  'hat'],\n",
       " 'ftr_10': ['sleep',\n",
       "  'rem',\n",
       "  'insomnia',\n",
       "  'eeg',\n",
       "  'circadian',\n",
       "  'syndrome',\n",
       "  'disorders',\n",
       "  'wake',\n",
       "  'night',\n",
       "  'deprivation',\n",
       "  'subjects',\n",
       "  'wakefulness',\n",
       "  'apnea',\n",
       "  'sleepiness',\n",
       "  'daytime',\n",
       "  'quality',\n",
       "  'osa',\n",
       "  'melatonin',\n",
       "  'rls',\n",
       "  'slow',\n",
       "  'light',\n",
       "  'phase',\n",
       "  'nrem',\n",
       "  'duration',\n",
       "  'frequency'],\n",
       " 'ftr_11': ['memory',\n",
       "  'cognitive',\n",
       "  'learning',\n",
       "  'task',\n",
       "  'performance',\n",
       "  'training',\n",
       "  'hippocampal',\n",
       "  'hippocampus',\n",
       "  'working',\n",
       "  'tasks',\n",
       "  'spatial',\n",
       "  'term',\n",
       "  'recognition',\n",
       "  'retrieval',\n",
       "  'impairment',\n",
       "  'deficits',\n",
       "  'verbal',\n",
       "  'participants',\n",
       "  'fear',\n",
       "  '1016',\n",
       "  'aging',\n",
       "  'encoding',\n",
       "  'recall',\n",
       "  'temporal',\n",
       "  'neurosci'],\n",
       " 'ftr_12': ['network',\n",
       "  'spike',\n",
       "  'synaptic',\n",
       "  'neural',\n",
       "  'input',\n",
       "  'frequency',\n",
       "  'models',\n",
       "  'networks',\n",
       "  'neuron',\n",
       "  'state',\n",
       "  'values',\n",
       "  'set',\n",
       "  'learning',\n",
       "  'firing',\n",
       "  'value',\n",
       "  'parameters',\n",
       "  'algorithm',\n",
       "  'method',\n",
       "  'phase',\n",
       "  'hz',\n",
       "  'dynamics',\n",
       "  'signal',\n",
       "  'connectivity',\n",
       "  'noise',\n",
       "  'spikes'],\n",
       " 'ftr_13': ['receptor',\n",
       "  'rats',\n",
       "  'receptors',\n",
       "  'induced',\n",
       "  'stress',\n",
       "  'dopamine',\n",
       "  'rat',\n",
       "  'cocaine',\n",
       "  '1016',\n",
       "  'activation',\n",
       "  'neurosci',\n",
       "  'drug',\n",
       "  'release',\n",
       "  'administration',\n",
       "  'glutamate',\n",
       "  'da',\n",
       "  'synaptic',\n",
       "  'animals',\n",
       "  'behavior',\n",
       "  'mg',\n",
       "  'kg',\n",
       "  'nmda',\n",
       "  'chronic',\n",
       "  'res',\n",
       "  'behavioral'],\n",
       " 'ftr_14': ['stroke',\n",
       "  'cerebral',\n",
       "  'risk',\n",
       "  'ischemic',\n",
       "  'acute',\n",
       "  'blood',\n",
       "  'artery',\n",
       "  'outcome',\n",
       "  'hemorrhage',\n",
       "  'vascular',\n",
       "  'flow',\n",
       "  'carotid',\n",
       "  'intracranial',\n",
       "  'therapy',\n",
       "  'aneurysms',\n",
       "  'ischemia',\n",
       "  'aneurysm',\n",
       "  'occlusion',\n",
       "  'ct',\n",
       "  '01',\n",
       "  'pressure',\n",
       "  'injury',\n",
       "  'trial',\n",
       "  'score',\n",
       "  'mortality'],\n",
       " 'ftr_2': ['protein',\n",
       "  'expression',\n",
       "  'gene',\n",
       "  'cell',\n",
       "  'genes',\n",
       "  'proteins',\n",
       "  'receptor',\n",
       "  'signaling',\n",
       "  'biol',\n",
       "  'binding',\n",
       "  'neuronal',\n",
       "  '1016',\n",
       "  'regulation',\n",
       "  'kinase',\n",
       "  'dna',\n",
       "  'mutations',\n",
       "  'factor',\n",
       "  'neurosci',\n",
       "  'mol',\n",
       "  'dependent',\n",
       "  'mouse',\n",
       "  'transcription',\n",
       "  'molecular',\n",
       "  'complex',\n",
       "  'rna'],\n",
       " 'ftr_3': ['depression',\n",
       "  'disorder',\n",
       "  'psychiatry',\n",
       "  'schizophrenia',\n",
       "  'disorders',\n",
       "  'symptoms',\n",
       "  'anxiety',\n",
       "  'bipolar',\n",
       "  'social',\n",
       "  'risk',\n",
       "  'depressive',\n",
       "  'children',\n",
       "  'health',\n",
       "  'cognitive',\n",
       "  'placebo',\n",
       "  'psychiatric',\n",
       "  'major',\n",
       "  'clin',\n",
       "  'stress',\n",
       "  'adhd',\n",
       "  'mental',\n",
       "  'life',\n",
       "  'mg',\n",
       "  'mood',\n",
       "  'scale'],\n",
       " 'ftr_4': ['cells',\n",
       "  'cell',\n",
       "  'fig',\n",
       "  'expression',\n",
       "  'stem',\n",
       "  'anti',\n",
       "  'μm',\n",
       "  'pituitary',\n",
       "  'il',\n",
       "  'growth',\n",
       "  'adult',\n",
       "  'rat',\n",
       "  'astrocytes',\n",
       "  'layer',\n",
       "  'positive',\n",
       "  'proliferation',\n",
       "  'differentiation',\n",
       "  'ml',\n",
       "  'microglia',\n",
       "  'tissue',\n",
       "  'cns',\n",
       "  'antibody',\n",
       "  'immune',\n",
       "  'factor',\n",
       "  'tumor'],\n",
       " 'ftr_5': ['cortex',\n",
       "  'regions',\n",
       "  'connectivity',\n",
       "  'cortical',\n",
       "  'matter',\n",
       "  'frontal',\n",
       "  'temporal',\n",
       "  'gyrus',\n",
       "  'areas',\n",
       "  'white',\n",
       "  'fmri',\n",
       "  'activation',\n",
       "  'network',\n",
       "  'neuroimage',\n",
       "  'volume',\n",
       "  'mri',\n",
       "  'area',\n",
       "  'subjects',\n",
       "  'motor',\n",
       "  'processing',\n",
       "  'region',\n",
       "  'anterior',\n",
       "  'controls',\n",
       "  '2012',\n",
       "  'parietal'],\n",
       " 'ftr_6': ['pain',\n",
       "  'spinal',\n",
       "  'nerve',\n",
       "  'injury',\n",
       "  'surgery',\n",
       "  'cord',\n",
       "  'motor',\n",
       "  'stimulation',\n",
       "  'months',\n",
       "  'sclerosis',\n",
       "  'mg',\n",
       "  'tumor',\n",
       "  'mri',\n",
       "  'surgical',\n",
       "  'therapy',\n",
       "  'ms',\n",
       "  'syndrome',\n",
       "  'epilepsy',\n",
       "  'symptoms',\n",
       "  'chronic',\n",
       "  'muscle',\n",
       "  'lesions',\n",
       "  'diagnosis',\n",
       "  'fig',\n",
       "  'neurosurg'],\n",
       " 'ftr_7': ['visual',\n",
       "  'task',\n",
       "  'stimulus',\n",
       "  'stimuli',\n",
       "  'trials',\n",
       "  'responses',\n",
       "  'ms',\n",
       "  'attention',\n",
       "  'participants',\n",
       "  'target',\n",
       "  'condition',\n",
       "  'processing',\n",
       "  'cortex',\n",
       "  'trial',\n",
       "  'conditions',\n",
       "  'subjects',\n",
       "  'reward',\n",
       "  'neural',\n",
       "  'experiment',\n",
       "  'auditory',\n",
       "  'error',\n",
       "  'fig',\n",
       "  'spatial',\n",
       "  'performance',\n",
       "  'eye'],\n",
       " 'ftr_8': ['mice',\n",
       "  'fig',\n",
       "  'mouse',\n",
       "  'wt',\n",
       "  'animals',\n",
       "  'expression',\n",
       "  'transgenic',\n",
       "  '05',\n",
       "  'wild',\n",
       "  'supplementary',\n",
       "  'min',\n",
       "  'ko',\n",
       "  'treated',\n",
       "  '01',\n",
       "  'anti',\n",
       "  'days',\n",
       "  'day',\n",
       "  'sections',\n",
       "  'mm',\n",
       "  'behavioral',\n",
       "  'mutant',\n",
       "  'cre',\n",
       "  'protein',\n",
       "  'μm',\n",
       "  'reduced'],\n",
       " 'ftr_9': ['ad',\n",
       "  'alzheimer',\n",
       "  'amyloid',\n",
       "  'dementia',\n",
       "  'cognitive',\n",
       "  'aβ',\n",
       "  'tau',\n",
       "  'impairment',\n",
       "  'beta',\n",
       "  'csf',\n",
       "  'pathology',\n",
       "  'aging',\n",
       "  'mci',\n",
       "  'app',\n",
       "  'subjects',\n",
       "  'protein',\n",
       "  'mild',\n",
       "  'risk',\n",
       "  'transgenic',\n",
       "  'neurology',\n",
       "  'parkinson',\n",
       "  'pd',\n",
       "  'plaques',\n",
       "  'pet',\n",
       "  'apoe']}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ftr_0</th>\n",
       "      <th>ftr_1</th>\n",
       "      <th>ftr_2</th>\n",
       "      <th>ftr_3</th>\n",
       "      <th>ftr_4</th>\n",
       "      <th>ftr_5</th>\n",
       "      <th>ftr_6</th>\n",
       "      <th>ftr_7</th>\n",
       "      <th>ftr_8</th>\n",
       "      <th>ftr_9</th>\n",
       "      <th>ftr_10</th>\n",
       "      <th>ftr_11</th>\n",
       "      <th>ftr_12</th>\n",
       "      <th>ftr_13</th>\n",
       "      <th>ftr_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023846</td>\n",
       "      <td>0.151433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348370</td>\n",
       "      <td>0.074328</td>\n",
       "      <td>0.430419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083146</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.052404</td>\n",
       "      <td>0.037374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.373538</td>\n",
       "      <td>1.566347</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077959</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189967</td>\n",
       "      <td>0.042379</td>\n",
       "      <td>0.005179</td>\n",
       "      <td>0.241411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139213</td>\n",
       "      <td>0.068895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208753</td>\n",
       "      <td>1.106872</td>\n",
       "      <td>0.278628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.284344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.919626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.723115</td>\n",
       "      <td>0.585271</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.049790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.173226</td>\n",
       "      <td>0.366277</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.241630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151733</td>\n",
       "      <td>0.020888</td>\n",
       "      <td>1.134157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.302243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321949</td>\n",
       "      <td>0.324857</td>\n",
       "      <td>0.219521</td>\n",
       "      <td>0.362776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475803</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.014115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006172</td>\n",
       "      <td>0.015128</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.033470</td>\n",
       "      <td>0.028787</td>\n",
       "      <td>0.014732</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074402</td>\n",
       "      <td>0.140909</td>\n",
       "      <td>0.013427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.043459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>0.010907</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.047067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047175</td>\n",
       "      <td>0.020128</td>\n",
       "      <td>0.052329</td>\n",
       "      <td>0.128085</td>\n",
       "      <td>0.142698</td>\n",
       "      <td>0.004206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.177763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.728721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.319955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.824188</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ftr_0     ftr_1     ftr_2     ftr_3     ftr_4     ftr_5     ftr_6  \\\n",
       "0  0.000000  0.000000  0.242059  0.000000  0.337031  0.000000  0.000000   \n",
       "1  0.001271  0.000000  0.348370  0.074328  0.430419  0.000000  0.083146   \n",
       "2  0.077959  0.009858  0.000000  0.000000  0.189967  0.042379  0.005179   \n",
       "3  0.284344  0.000000  0.000000  0.000000  0.919626  0.000000  0.556786   \n",
       "4  0.049790  0.000000  0.091784  0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.241630  0.000000  0.151733  0.020888  1.134157  0.000000  0.021594   \n",
       "6  0.302243  0.000000  0.321949  0.324857  0.219521  0.362776  0.000000   \n",
       "7  0.014115  0.000000  0.000000  0.006172  0.015128  0.000343  0.033470   \n",
       "8  0.043459  0.000000  0.006222  0.010907  0.000881  0.047067  0.000000   \n",
       "9  0.177763  0.000000  0.728721  0.000000  0.348380  0.000000  0.424813   \n",
       "\n",
       "      ftr_7     ftr_8     ftr_9    ftr_10    ftr_11    ftr_12    ftr_13  \\\n",
       "0  0.006168  0.000000  0.000000  0.000000  0.023846  0.151433  0.000000   \n",
       "1  0.039900  0.052404  0.037374  0.000000  0.000000  0.373538  1.566347   \n",
       "2  0.241411  0.000000  0.139213  0.068895  0.000000  0.208753  1.106872   \n",
       "3  0.000000  0.222346  0.000000  0.037143  0.000000  0.723115  0.585271   \n",
       "4  0.000000  0.072251  0.000000  0.000000  0.025236  0.173226  0.366277   \n",
       "5  0.000000  0.000000  0.001079  0.000000  0.010628  0.007580  0.000000   \n",
       "6  0.000000  0.636583  0.000000  0.000000  0.000000  0.000000  0.475803   \n",
       "7  0.028787  0.014732  0.002245  0.000150  0.000000  0.074402  0.140909   \n",
       "8  0.061867  0.000000  0.047175  0.020128  0.052329  0.128085  0.142698   \n",
       "9  0.000000  0.319955  0.000000  0.000000  0.000000  0.000000  0.824188   \n",
       "\n",
       "     ftr_14  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.278628  \n",
       "3  0.000000  \n",
       "4  0.000000  \n",
       "5  0.000000  \n",
       "6  0.000000  \n",
       "7  0.013427  \n",
       "8  0.004206  \n",
       "9  0.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_nmf = pd.DataFrame(nmf.transform(txt_ftrs), columns = ['ftr_' + str(i) for i in range(len(top25.keys()))])\n",
    "getsizeof(text_nmf) # 3mb\n",
    "text_nmf.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "components_df = pd.DataFrame(top25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ftr_0</th>\n",
       "      <th>ftr_1</th>\n",
       "      <th>ftr_10</th>\n",
       "      <th>ftr_11</th>\n",
       "      <th>ftr_12</th>\n",
       "      <th>ftr_13</th>\n",
       "      <th>ftr_14</th>\n",
       "      <th>ftr_2</th>\n",
       "      <th>ftr_3</th>\n",
       "      <th>ftr_4</th>\n",
       "      <th>ftr_5</th>\n",
       "      <th>ftr_6</th>\n",
       "      <th>ftr_7</th>\n",
       "      <th>ftr_8</th>\n",
       "      <th>ftr_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>area</td>\n",
       "      <td>12pt</td>\n",
       "      <td>apnea</td>\n",
       "      <td>1016</td>\n",
       "      <td>algorithm</td>\n",
       "      <td>1016</td>\n",
       "      <td>01</td>\n",
       "      <td>1016</td>\n",
       "      <td>adhd</td>\n",
       "      <td>adult</td>\n",
       "      <td>2012</td>\n",
       "      <td>chronic</td>\n",
       "      <td>attention</td>\n",
       "      <td>01</td>\n",
       "      <td>ad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cortex</td>\n",
       "      <td>69pt</td>\n",
       "      <td>circadian</td>\n",
       "      <td>aging</td>\n",
       "      <td>connectivity</td>\n",
       "      <td>activation</td>\n",
       "      <td>acute</td>\n",
       "      <td>binding</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>anti</td>\n",
       "      <td>activation</td>\n",
       "      <td>cord</td>\n",
       "      <td>auditory</td>\n",
       "      <td>05</td>\n",
       "      <td>aging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cortical</td>\n",
       "      <td>amsbsy</td>\n",
       "      <td>daytime</td>\n",
       "      <td>cognitive</td>\n",
       "      <td>dynamics</td>\n",
       "      <td>administration</td>\n",
       "      <td>aneurysm</td>\n",
       "      <td>biol</td>\n",
       "      <td>bipolar</td>\n",
       "      <td>antibody</td>\n",
       "      <td>anterior</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>condition</td>\n",
       "      <td>animals</td>\n",
       "      <td>alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dendritic</td>\n",
       "      <td>amsfonts</td>\n",
       "      <td>deprivation</td>\n",
       "      <td>deficits</td>\n",
       "      <td>firing</td>\n",
       "      <td>animals</td>\n",
       "      <td>aneurysms</td>\n",
       "      <td>cell</td>\n",
       "      <td>children</td>\n",
       "      <td>astrocytes</td>\n",
       "      <td>area</td>\n",
       "      <td>epilepsy</td>\n",
       "      <td>conditions</td>\n",
       "      <td>anti</td>\n",
       "      <td>amyloid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>excitatory</td>\n",
       "      <td>amsmath</td>\n",
       "      <td>disorders</td>\n",
       "      <td>encoding</td>\n",
       "      <td>frequency</td>\n",
       "      <td>behavior</td>\n",
       "      <td>artery</td>\n",
       "      <td>complex</td>\n",
       "      <td>clin</td>\n",
       "      <td>cell</td>\n",
       "      <td>areas</td>\n",
       "      <td>fig</td>\n",
       "      <td>cortex</td>\n",
       "      <td>behavioral</td>\n",
       "      <td>app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fig</td>\n",
       "      <td>amssymb</td>\n",
       "      <td>duration</td>\n",
       "      <td>fear</td>\n",
       "      <td>hz</td>\n",
       "      <td>chronic</td>\n",
       "      <td>blood</td>\n",
       "      <td>dependent</td>\n",
       "      <td>cognitive</td>\n",
       "      <td>cells</td>\n",
       "      <td>connectivity</td>\n",
       "      <td>injury</td>\n",
       "      <td>error</td>\n",
       "      <td>cre</td>\n",
       "      <td>aβ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>firing</td>\n",
       "      <td>begin</td>\n",
       "      <td>eeg</td>\n",
       "      <td>hippocampal</td>\n",
       "      <td>input</td>\n",
       "      <td>cocaine</td>\n",
       "      <td>carotid</td>\n",
       "      <td>dna</td>\n",
       "      <td>depression</td>\n",
       "      <td>cns</td>\n",
       "      <td>controls</td>\n",
       "      <td>lesions</td>\n",
       "      <td>experiment</td>\n",
       "      <td>day</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gabaergic</td>\n",
       "      <td>document</td>\n",
       "      <td>insomnia</td>\n",
       "      <td>hippocampus</td>\n",
       "      <td>learning</td>\n",
       "      <td>da</td>\n",
       "      <td>cerebral</td>\n",
       "      <td>expression</td>\n",
       "      <td>depressive</td>\n",
       "      <td>differentiation</td>\n",
       "      <td>cortex</td>\n",
       "      <td>mg</td>\n",
       "      <td>fig</td>\n",
       "      <td>days</td>\n",
       "      <td>cognitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>inhibitory</td>\n",
       "      <td>documentclass</td>\n",
       "      <td>light</td>\n",
       "      <td>impairment</td>\n",
       "      <td>method</td>\n",
       "      <td>dopamine</td>\n",
       "      <td>ct</td>\n",
       "      <td>factor</td>\n",
       "      <td>disorder</td>\n",
       "      <td>expression</td>\n",
       "      <td>cortical</td>\n",
       "      <td>months</td>\n",
       "      <td>ms</td>\n",
       "      <td>expression</td>\n",
       "      <td>csf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>input</td>\n",
       "      <td>end</td>\n",
       "      <td>melatonin</td>\n",
       "      <td>learning</td>\n",
       "      <td>models</td>\n",
       "      <td>drug</td>\n",
       "      <td>flow</td>\n",
       "      <td>gene</td>\n",
       "      <td>disorders</td>\n",
       "      <td>factor</td>\n",
       "      <td>fmri</td>\n",
       "      <td>motor</td>\n",
       "      <td>neural</td>\n",
       "      <td>fig</td>\n",
       "      <td>dementia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>interneurons</td>\n",
       "      <td>eq</td>\n",
       "      <td>night</td>\n",
       "      <td>memory</td>\n",
       "      <td>network</td>\n",
       "      <td>glutamate</td>\n",
       "      <td>hemorrhage</td>\n",
       "      <td>genes</td>\n",
       "      <td>health</td>\n",
       "      <td>fig</td>\n",
       "      <td>frontal</td>\n",
       "      <td>mri</td>\n",
       "      <td>participants</td>\n",
       "      <td>ko</td>\n",
       "      <td>impairment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>layer</td>\n",
       "      <td>fig</td>\n",
       "      <td>nrem</td>\n",
       "      <td>participants</td>\n",
       "      <td>networks</td>\n",
       "      <td>induced</td>\n",
       "      <td>injury</td>\n",
       "      <td>kinase</td>\n",
       "      <td>life</td>\n",
       "      <td>growth</td>\n",
       "      <td>gyrus</td>\n",
       "      <td>ms</td>\n",
       "      <td>performance</td>\n",
       "      <td>mice</td>\n",
       "      <td>mci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>neuron</td>\n",
       "      <td>frac</td>\n",
       "      <td>osa</td>\n",
       "      <td>performance</td>\n",
       "      <td>neural</td>\n",
       "      <td>kg</td>\n",
       "      <td>intracranial</td>\n",
       "      <td>mol</td>\n",
       "      <td>major</td>\n",
       "      <td>il</td>\n",
       "      <td>matter</td>\n",
       "      <td>muscle</td>\n",
       "      <td>processing</td>\n",
       "      <td>min</td>\n",
       "      <td>mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>neuronal</td>\n",
       "      <td>mathrm</td>\n",
       "      <td>phase</td>\n",
       "      <td>recall</td>\n",
       "      <td>neuron</td>\n",
       "      <td>mg</td>\n",
       "      <td>ischemia</td>\n",
       "      <td>molecular</td>\n",
       "      <td>mental</td>\n",
       "      <td>immune</td>\n",
       "      <td>motor</td>\n",
       "      <td>nerve</td>\n",
       "      <td>responses</td>\n",
       "      <td>mm</td>\n",
       "      <td>neurology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>neurons</td>\n",
       "      <td>mathrsfs</td>\n",
       "      <td>quality</td>\n",
       "      <td>recognition</td>\n",
       "      <td>noise</td>\n",
       "      <td>neurosci</td>\n",
       "      <td>ischemic</td>\n",
       "      <td>mouse</td>\n",
       "      <td>mg</td>\n",
       "      <td>layer</td>\n",
       "      <td>mri</td>\n",
       "      <td>pain</td>\n",
       "      <td>reward</td>\n",
       "      <td>mouse</td>\n",
       "      <td>parkinson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>neurosci</td>\n",
       "      <td>minimal</td>\n",
       "      <td>rem</td>\n",
       "      <td>retrieval</td>\n",
       "      <td>parameters</td>\n",
       "      <td>nmda</td>\n",
       "      <td>occlusion</td>\n",
       "      <td>mutations</td>\n",
       "      <td>mood</td>\n",
       "      <td>microglia</td>\n",
       "      <td>network</td>\n",
       "      <td>sclerosis</td>\n",
       "      <td>spatial</td>\n",
       "      <td>mutant</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nucleus</td>\n",
       "      <td>oddsidemargin</td>\n",
       "      <td>rls</td>\n",
       "      <td>spatial</td>\n",
       "      <td>phase</td>\n",
       "      <td>rat</td>\n",
       "      <td>outcome</td>\n",
       "      <td>neuronal</td>\n",
       "      <td>placebo</td>\n",
       "      <td>ml</td>\n",
       "      <td>neuroimage</td>\n",
       "      <td>spinal</td>\n",
       "      <td>stimuli</td>\n",
       "      <td>protein</td>\n",
       "      <td>pd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pyramidal</td>\n",
       "      <td>setlength</td>\n",
       "      <td>sleep</td>\n",
       "      <td>task</td>\n",
       "      <td>set</td>\n",
       "      <td>rats</td>\n",
       "      <td>pressure</td>\n",
       "      <td>neurosci</td>\n",
       "      <td>psychiatric</td>\n",
       "      <td>pituitary</td>\n",
       "      <td>processing</td>\n",
       "      <td>stimulation</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>sections</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rat</td>\n",
       "      <td>sf</td>\n",
       "      <td>sleepiness</td>\n",
       "      <td>tasks</td>\n",
       "      <td>signal</td>\n",
       "      <td>receptor</td>\n",
       "      <td>risk</td>\n",
       "      <td>protein</td>\n",
       "      <td>psychiatry</td>\n",
       "      <td>positive</td>\n",
       "      <td>region</td>\n",
       "      <td>surgery</td>\n",
       "      <td>subjects</td>\n",
       "      <td>supplementary</td>\n",
       "      <td>plaques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>responses</td>\n",
       "      <td>spike</td>\n",
       "      <td>slow</td>\n",
       "      <td>temporal</td>\n",
       "      <td>spike</td>\n",
       "      <td>receptors</td>\n",
       "      <td>score</td>\n",
       "      <td>proteins</td>\n",
       "      <td>risk</td>\n",
       "      <td>proliferation</td>\n",
       "      <td>regions</td>\n",
       "      <td>surgical</td>\n",
       "      <td>target</td>\n",
       "      <td>transgenic</td>\n",
       "      <td>protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>stimulation</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>subjects</td>\n",
       "      <td>term</td>\n",
       "      <td>state</td>\n",
       "      <td>release</td>\n",
       "      <td>stroke</td>\n",
       "      <td>receptor</td>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>rat</td>\n",
       "      <td>subjects</td>\n",
       "      <td>symptoms</td>\n",
       "      <td>task</td>\n",
       "      <td>treated</td>\n",
       "      <td>risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>synaptic</td>\n",
       "      <td>upgreek</td>\n",
       "      <td>syndrome</td>\n",
       "      <td>training</td>\n",
       "      <td>synaptic</td>\n",
       "      <td>res</td>\n",
       "      <td>therapy</td>\n",
       "      <td>regulation</td>\n",
       "      <td>social</td>\n",
       "      <td>stem</td>\n",
       "      <td>temporal</td>\n",
       "      <td>syndrome</td>\n",
       "      <td>trial</td>\n",
       "      <td>wild</td>\n",
       "      <td>subjects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>visual</td>\n",
       "      <td>usepackage</td>\n",
       "      <td>wake</td>\n",
       "      <td>verbal</td>\n",
       "      <td>value</td>\n",
       "      <td>stress</td>\n",
       "      <td>trial</td>\n",
       "      <td>signaling</td>\n",
       "      <td>stress</td>\n",
       "      <td>tissue</td>\n",
       "      <td>volume</td>\n",
       "      <td>therapy</td>\n",
       "      <td>trials</td>\n",
       "      <td>wt</td>\n",
       "      <td>tau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>μm</td>\n",
       "      <td>wasysym</td>\n",
       "      <td>wakefulness</td>\n",
       "      <td>working</td>\n",
       "      <td>values</td>\n",
       "      <td>synaptic</td>\n",
       "      <td>vascular</td>\n",
       "      <td>transcription</td>\n",
       "      <td>symptoms</td>\n",
       "      <td>μm</td>\n",
       "      <td>white</td>\n",
       "      <td>tumor</td>\n",
       "      <td>visual</td>\n",
       "      <td>μm</td>\n",
       "      <td>transgenic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ftr_0          ftr_1       ftr_10        ftr_11        ftr_12  \\\n",
       "0           area           12pt        apnea          1016     algorithm   \n",
       "1         cortex           69pt    circadian         aging  connectivity   \n",
       "2       cortical         amsbsy      daytime     cognitive      dynamics   \n",
       "3      dendritic       amsfonts  deprivation      deficits        firing   \n",
       "4     excitatory        amsmath    disorders      encoding     frequency   \n",
       "5            fig        amssymb     duration          fear            hz   \n",
       "6         firing          begin          eeg   hippocampal         input   \n",
       "7      gabaergic       document     insomnia   hippocampus      learning   \n",
       "8     inhibitory  documentclass        light    impairment        method   \n",
       "9          input            end    melatonin      learning        models   \n",
       "10  interneurons             eq        night        memory       network   \n",
       "11         layer            fig         nrem  participants      networks   \n",
       "12        neuron           frac          osa   performance        neural   \n",
       "13      neuronal         mathrm        phase        recall        neuron   \n",
       "14       neurons       mathrsfs      quality   recognition         noise   \n",
       "15      neurosci        minimal          rem     retrieval    parameters   \n",
       "16       nucleus  oddsidemargin          rls       spatial         phase   \n",
       "17     pyramidal      setlength        sleep          task           set   \n",
       "18           rat             sf   sleepiness         tasks        signal   \n",
       "19     responses          spike         slow      temporal         spike   \n",
       "20   stimulation       stimulus     subjects          term         state   \n",
       "21      synaptic        upgreek     syndrome      training      synaptic   \n",
       "22        visual     usepackage         wake        verbal         value   \n",
       "23            μm        wasysym  wakefulness       working        values   \n",
       "\n",
       "            ftr_13        ftr_14          ftr_2          ftr_3  \\\n",
       "0             1016            01           1016           adhd   \n",
       "1       activation         acute        binding        anxiety   \n",
       "2   administration      aneurysm           biol        bipolar   \n",
       "3          animals     aneurysms           cell       children   \n",
       "4         behavior        artery        complex           clin   \n",
       "5          chronic         blood      dependent      cognitive   \n",
       "6          cocaine       carotid            dna     depression   \n",
       "7               da      cerebral     expression     depressive   \n",
       "8         dopamine            ct         factor       disorder   \n",
       "9             drug          flow           gene      disorders   \n",
       "10       glutamate    hemorrhage          genes         health   \n",
       "11         induced        injury         kinase           life   \n",
       "12              kg  intracranial            mol          major   \n",
       "13              mg      ischemia      molecular         mental   \n",
       "14        neurosci      ischemic          mouse             mg   \n",
       "15            nmda     occlusion      mutations           mood   \n",
       "16             rat       outcome       neuronal        placebo   \n",
       "17            rats      pressure       neurosci    psychiatric   \n",
       "18        receptor          risk        protein     psychiatry   \n",
       "19       receptors         score       proteins           risk   \n",
       "20         release        stroke       receptor  schizophrenia   \n",
       "21             res       therapy     regulation         social   \n",
       "22          stress         trial      signaling         stress   \n",
       "23        synaptic      vascular  transcription       symptoms   \n",
       "\n",
       "              ftr_4         ftr_5        ftr_6         ftr_7          ftr_8  \\\n",
       "0             adult          2012      chronic     attention             01   \n",
       "1              anti    activation         cord      auditory             05   \n",
       "2          antibody      anterior    diagnosis     condition        animals   \n",
       "3        astrocytes          area     epilepsy    conditions           anti   \n",
       "4              cell         areas          fig        cortex     behavioral   \n",
       "5             cells  connectivity       injury         error            cre   \n",
       "6               cns      controls      lesions    experiment            day   \n",
       "7   differentiation        cortex           mg           fig           days   \n",
       "8        expression      cortical       months            ms     expression   \n",
       "9            factor          fmri        motor        neural            fig   \n",
       "10              fig       frontal          mri  participants             ko   \n",
       "11           growth         gyrus           ms   performance           mice   \n",
       "12               il        matter       muscle    processing            min   \n",
       "13           immune         motor        nerve     responses             mm   \n",
       "14            layer           mri         pain        reward          mouse   \n",
       "15        microglia       network    sclerosis       spatial         mutant   \n",
       "16               ml    neuroimage       spinal       stimuli        protein   \n",
       "17        pituitary    processing  stimulation      stimulus       sections   \n",
       "18         positive        region      surgery      subjects  supplementary   \n",
       "19    proliferation       regions     surgical        target     transgenic   \n",
       "20              rat      subjects     symptoms          task        treated   \n",
       "21             stem      temporal     syndrome         trial           wild   \n",
       "22           tissue        volume      therapy        trials             wt   \n",
       "23               μm         white        tumor        visual             μm   \n",
       "\n",
       "         ftr_9  \n",
       "0           ad  \n",
       "1        aging  \n",
       "2    alzheimer  \n",
       "3      amyloid  \n",
       "4          app  \n",
       "5           aβ  \n",
       "6         beta  \n",
       "7    cognitive  \n",
       "8          csf  \n",
       "9     dementia  \n",
       "10  impairment  \n",
       "11         mci  \n",
       "12        mild  \n",
       "13   neurology  \n",
       "14   parkinson  \n",
       "15   pathology  \n",
       "16          pd  \n",
       "17         pet  \n",
       "18     plaques  \n",
       "19     protein  \n",
       "20        risk  \n",
       "21    subjects  \n",
       "22         tau  \n",
       "23  transgenic  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getsizeof(components_df) # 23kb\n",
    "components_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# text_data, cleaned, cvectr, nmf, text_nmf, components_df\n",
    "with open('WranglingPickles/text_data.pkl','wb') as f:\n",
    "    pickle.dump(text_data, f)\n",
    "    \n",
    "with open('WranglingPickles/cleaned.pkl','wb') as f:\n",
    "    pickle.dump(cleaned, f)\n",
    "    \n",
    "with open('WranglingPickles/cvectr.pkl','wb') as f:\n",
    "    pickle.dump(cvectr, f)\n",
    "    \n",
    "with open('WranglingPickles/nmf.pkl','wb') as f:\n",
    "    pickle.dump(nmf, f)\n",
    "    \n",
    "with open('WranglingPickles/text_nmf.pkl','wb') as f:\n",
    "    pickle.dump(text_nmf, f)\n",
    "    \n",
    "with open('WranglingPickles/components_df.pkl','wb') as f:\n",
    "    pickle.dump(components_df, f)\n",
    "    \n",
    "with open('WranglingPickles/Joined.pkl','wb') as f:\n",
    "    pickle.dump(Joined, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
